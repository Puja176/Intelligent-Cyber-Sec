{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled48.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Puja176/Intelligent-Cyber-Sec/blob/master/Membership_Attack1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIX5BKXdtSaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEeDt8GHtYde",
        "colab_type": "code",
        "outputId": "12bf98b0-26af-4280-f4e5-9f0c3fd280a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/UMKC/Cybersecurity/ICP-66'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vNxyY-Btb0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puS3eD9htkgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LByVyB1Vtlmx",
        "colab_type": "code",
        "outputId": "26dfb60c-d350-4dc1-b7f7-1f8bc6c313d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.STL10(root= project_path+'/data', \n",
        "                                        split='train' ,download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.STL10(root= project_path+'/data', \n",
        "                                        split='test',download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('whale', 'shark', 'roses', 'cans', 'oranges', 'lamp', 'table', 'butterfly', 'lion', 'house')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV4xyCUytomT",
        "colab_type": "code",
        "outputId": "fd439f09-7b27-47cc-b2fc-a2f0bddfd28b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "#print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\negAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yTuuJrDtrNR",
        "colab_type": "code",
        "outputId": "b440d68a-8e2e-49a9-90e8-0b149ffe3094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000 1250 2500 3750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4L-oKOStuHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2QU0jXIt0qB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpcTAd7Vt1ap",
        "colab_type": "code",
        "outputId": "3bd31146-0b52-4379-e618-722908dbc6b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6N2gofAt3vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a94_FCWyt6JF",
        "colab_type": "code",
        "outputId": "38fb7214-c617-46b9-d56d-af571b1e66fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow1_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 2.2397332704519926\n",
            "\n",
            "Epoch : 2/20.. Training loss: 2.1108391405660893\n",
            "\n",
            "Epoch : 3/20.. Training loss: 2.04982962638517\n",
            "\n",
            "Epoch : 4/20.. Training loss: 2.01755137684979\n",
            "\n",
            "Epoch : 5/20.. Training loss: 2.0349248285535015\n",
            "\n",
            "Epoch : 6/20.. Training loss: 2.0125163401229473\n",
            "\n",
            "Epoch : 7/20.. Training loss: 1.9996690327608133\n",
            "\n",
            "Epoch : 8/20.. Training loss: 1.9504621360875383\n",
            "\n",
            "Epoch : 9/20.. Training loss: 1.9365346990054166\n",
            "\n",
            "Epoch : 10/20.. Training loss: 1.9292624962480762\n",
            "\n",
            "Epoch : 11/20.. Training loss: 1.9621957706499704\n",
            "\n",
            "Epoch : 12/20.. Training loss: 1.927135381517531\n",
            "\n",
            "Epoch : 13/20.. Training loss: 1.9054679463181314\n",
            "\n",
            "Epoch : 14/20.. Training loss: 1.9198198997521703\n",
            "\n",
            "Epoch : 15/20.. Training loss: 1.899045541316648\n",
            "\n",
            "Epoch : 16/20.. Training loss: 1.9369235114206242\n",
            "\n",
            "Epoch : 17/20.. Training loss: 1.9138198668443704\n",
            "\n",
            "Epoch : 18/20.. Training loss: 1.892343693141696\n",
            "\n",
            "Epoch : 19/20.. Training loss: 1.906880882721913\n",
            "\n",
            "Epoch : 20/20.. Training loss: 1.9098955091041854\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRLEyQNBt9Zw",
        "colab_type": "code",
        "outputId": "a09719a2-59a8-4a25-e39a-ca0b5cf67853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9KjsixFuAm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90MchoUAuDEz",
        "colab_type": "code",
        "outputId": "e190eda8-810f-4770-c3f1-5b86e408ded4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow1_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[2000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([0.09056915, 0.17454015, 0.04508923, 0.11724278, 0.10316083,\n",
            "       0.13473624, 0.1071687 , 0.10118535, 0.05865627, 0.06765126],\n",
            "      dtype=float32), 1]\n",
            "[array([0.1371661 , 0.10821615, 0.14031759, 0.06336891, 0.05353362,\n",
            "       0.07685729, 0.08907619, 0.05861205, 0.12900916, 0.14384304],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cNgimaHuFl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow1.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8RSArgduIAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/shadow1_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target1.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMldE5GuuK4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target1.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKNpGgKxuNSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow1.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCYB1GrduPN1",
        "colab_type": "code",
        "outputId": "2982689b-b2be-4f24-e545-2adcca33d349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 2500 and No.of test data 625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROjpfclVuRw-",
        "colab_type": "code",
        "outputId": "e4f2c086-1c37-40a1-c95f-8298c1dee350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack1_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06941141719818116\n",
            "Training loss: 0.06935809502601624\n",
            "Training loss: 0.06937127656936645\n",
            "Training loss: 0.0693600853919983\n",
            "Training loss: 0.0693547751903534\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2AIxulQuUpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target1.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25UV4nm7uW2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[500:2500]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljb29xhnuZDw",
        "colab_type": "code",
        "outputId": "10c22747-0084-4d63-b915-6579a2356a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "if((tp+fp)!=0):\n",
        "  pre = tp/(tp+fp)\n",
        "if((tp+fn)!=0):\n",
        "  rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 750, TN : 0, FP : 1250, FN : 0\n",
            "Precision 37.5\n",
            "Recall 100.0\n",
            "F1 Score 54.54545454545454\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}